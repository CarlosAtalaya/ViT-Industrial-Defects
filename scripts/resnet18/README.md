# DetecciÃ³n de Defectos Industriales con ResNet-18 + Faster R-CNN

Sistema de detecciÃ³n de defectos en componentes industriales usando ResNet-18 como backbone en un modelo Faster R-CNN para detecciÃ³n multiclase.

## ðŸ“‹ DescripciÃ³n

Este proyecto implementa un pipeline completo de entrenamiento y evaluaciÃ³n para detecciÃ³n de defectos industriales con las siguientes caracterÃ­sticas:

- **Arquitectura**: ResNet-18 (preentrenado en ImageNet) + Faster R-CNN
- **Tarea**: DetecciÃ³n multiclase de defectos (6 categorÃ­as + NORMAL)
- **CategorÃ­as de defectos**:
  - NORMAL (sin defectos)
  - ROTURA_FRACTURA
  - PERFORACIONES
  - RAYONES_ARANAZOS
  - DEFORMACIONES
  - CONTAMINACION

- **Dataset**: Formato COCO con anotaciones en bounding boxes
- **MÃ©tricas**: mAP (mean Average Precision), Precision, Recall por clase

## ðŸ—‚ï¸ Estructura de Archivos

```
.
â”œâ”€â”€ industrial_defects_dataset.py    # Dataset loader (COCO format)
â”œâ”€â”€ train_resnet18_fasterrcnn.py    # Script de entrenamiento
â”œâ”€â”€ evaluate_model.py                # EvaluaciÃ³n con mÃ©tricas mAP
â”œâ”€â”€ visualize_predictions.py         # VisualizaciÃ³n de predicciones
â”œâ”€â”€ plot_training_metrics.py         # GrÃ¡ficas de mÃ©tricas de entrenamiento
â”œâ”€â”€ run_pipeline.sh                  # Script para ejecutar pipeline completo
â””â”€â”€ README.md                        # Este archivo
```

## ðŸ“Š EstadÃ­sticas del Dataset

### Train Set (715 imÃ¡genes)
- NORMAL: 210 imÃ¡genes
- ROTURA_FRACTURA: 118 imÃ¡genes
- PERFORACIONES: 106 imÃ¡genes
- RAYONES_ARANAZOS: 105 imÃ¡genes
- DEFORMACIONES: 94 imÃ¡genes
- CONTAMINACION: 85 imÃ¡genes

### Val Set (102 imÃ¡genes)
- NORMAL: 30 imÃ¡genes
- ROTURA_FRACTURA: 17 imÃ¡genes
- PERFORACIONES: 15 imÃ¡genes
- RAYONES_ARANAZOS: 15 imÃ¡genes
- DEFORMACIONES: 13 imÃ¡genes
- CONTAMINACION: 13 imÃ¡genes

### Test Set (205 imÃ¡genes)
- NORMAL: 60 imÃ¡genes
- ROTURA_FRACTURA: 34 imÃ¡genes
- RAYONES_ARANAZOS: 32 imÃ¡genes
- PERFORACIONES: 31 imÃ¡genes
- DEFORMACIONES: 26 imÃ¡genes
- CONTAMINACION: 24 imÃ¡genes

## ðŸš€ InstalaciÃ³n

### Requisitos

```bash
# PyTorch (con CUDA si estÃ¡ disponible)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Otras dependencias
pip install numpy matplotlib pillow tqdm
```

### Verificar instalaciÃ³n

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')"
```

## ðŸ’» Uso

### OpciÃ³n 1: Pipeline Completo (Recomendado)

Ejecutar el pipeline completo de entrenamiento, evaluaciÃ³n y visualizaciÃ³n:

```bash
chmod +x run_pipeline.sh
./run_pipeline.sh
```

Este script ejecutarÃ¡ automÃ¡ticamente:
1. Entrenamiento del modelo
2. VisualizaciÃ³n de mÃ©tricas de entrenamiento
3. EvaluaciÃ³n en conjunto de test
4. VisualizaciÃ³n de predicciones en imÃ¡genes de test

### OpciÃ³n 2: EjecuciÃ³n Manual por Pasos

#### 1. Entrenamiento

```bash
python train_resnet18_fasterrcnn.py \
    --dataset-path curated_dataset_splitted_20251101_provisional_1st_version \
    --epochs 20 \
    --batch-size 4 \
    --lr 0.005 \
    --num-workers 4 \
    --pretrained-backbone \
    --output-dir results/training
```

**ParÃ¡metros principales:**
- `--dataset-path`: Ruta al dataset
- `--epochs`: NÃºmero de Ã©pocas (default: 20)
- `--batch-size`: TamaÃ±o del batch (default: 4)
- `--lr`: Learning rate inicial (default: 0.005)
- `--pretrained-backbone`: Usar ResNet-18 preentrenado en ImageNet
- `--lr-step-size`: Reducir LR cada N Ã©pocas (default: 5)
- `--lr-gamma`: Factor de reducciÃ³n de LR (default: 0.1)

**Outputs:**
- `results/training/resnet18_fasterrcnn_TIMESTAMP/`
  - `config.json`: ConfiguraciÃ³n del experimento
  - `training_history.json`: MÃ©tricas por Ã©poca
  - `checkpoints/`:
    - `best_checkpoint.pth`: Mejor modelo (menor val_loss)
    - `last_checkpoint.pth`: Ãšltimo checkpoint
    - `checkpoint_epoch_N.pth`: Checkpoints periÃ³dicos

#### 2. Visualizar MÃ©tricas de Entrenamiento

```bash
python plot_training_metrics.py \
    --history-path results/training/resnet18_fasterrcnn_TIMESTAMP/training_history.json
```

Genera grÃ¡ficas de:
- PÃ©rdida total (train/val)
- PÃ©rdida del clasificador
- PÃ©rdida de regresiÃ³n de bbox
- PÃ©rdida de objectness (RPN)
- PÃ©rdida de RPN bbox regression
- Learning rate schedule

#### 3. EvaluaciÃ³n en Test Set

```bash
python evaluate_model.py \
    --checkpoint results/training/resnet18_fasterrcnn_TIMESTAMP/checkpoints/best_checkpoint.pth \
    --dataset-path curated_dataset_splitted_20251101_provisional_1st_version \
    --batch-size 4 \
    --score-threshold 0.5 \
    --iou-threshold 0.5
```

**ParÃ¡metros:**
- `--checkpoint`: Ruta al checkpoint del modelo
- `--score-threshold`: Umbral de confianza para filtrar predicciones (default: 0.5)
- `--iou-threshold`: Umbral de IoU para considerar True Positive (default: 0.5)

**MÃ©tricas calculadas:**
- **mAP** (mean Average Precision): MÃ©trica principal
- **AP por clase**: Average Precision para cada categorÃ­a
- **Precision por clase**: PrecisiÃ³n final
- **Recall por clase**: Recall final

**Output:**
- `test_evaluation_results.json`: Resultados en formato JSON

#### 4. Visualizar Predicciones

```bash
python visualize_predictions.py \
    --checkpoint results/training/resnet18_fasterrcnn_TIMESTAMP/checkpoints/best_checkpoint.pth \
    --dataset-path curated_dataset_splitted_20251101_provisional_1st_version \
    --split test \
    --num-images 20 \
    --random \
    --score-threshold 0.5
```

**ParÃ¡metros:**
- `--split`: Conjunto a visualizar (train/val/test)
- `--num-images`: NÃºmero de imÃ¡genes a visualizar (-1 para todas)
- `--random`: Seleccionar imÃ¡genes aleatoriamente
- `--score-threshold`: Umbral de confianza

**Output:**
- `visualizations_test/`: ImÃ¡genes con predicciones y ground truth lado a lado

## ðŸ“ˆ InterpretaciÃ³n de Resultados

### MÃ©tricas de Entrenamiento

Durante el entrenamiento, se monitorizan las siguientes pÃ©rdidas:

1. **loss_classifier**: Error en la clasificaciÃ³n de objetos detectados
2. **loss_box_reg**: Error en la regresiÃ³n de bounding boxes
3. **loss_objectness**: Error de la RPN en detectar si hay objetos
4. **loss_rpn_box_reg**: Error de la RPN en ajustar propuestas de cajas

Una buena convergencia se observa cuando:
- Las pÃ©rdidas disminuyen gradualmente
- La pÃ©rdida de validaciÃ³n sigue la pÃ©rdida de entrenamiento
- No hay overfitting (val_loss aumenta mientras train_loss baja)

### MÃ©tricas de EvaluaciÃ³n (mAP)

- **mAP > 0.7**: Excelente rendimiento
- **mAP 0.5-0.7**: Buen rendimiento
- **mAP 0.3-0.5**: Rendimiento aceptable
- **mAP < 0.3**: Necesita mejora

**Nota**: El mAP depende del umbral de IoU. IoU=0.5 es estÃ¡ndar para COCO.

## ðŸ”§ HiperparÃ¡metros Recomendados

### Para Dataset PequeÃ±o (<1000 imÃ¡genes)

```bash
--epochs 30
--batch-size 4
--lr 0.005
--lr-step-size 10
--pretrained-backbone  # IMPORTANTE: siempre usar preentrenado
```

### Para Dataset Mediano (1000-5000 imÃ¡genes)

```bash
--epochs 25
--batch-size 8
--lr 0.005
--lr-step-size 8
```

### Si tienes problemas de memoria GPU

```bash
--batch-size 2  # Reducir batch size
--num-workers 2  # Reducir workers
```

## ðŸŽ¯ PrÃ³ximos Pasos para tu TFG

### 1. Experimentos Adicionales con CNNs ClÃ¡sicas

#### EfficientNet

Crear un script similar pero con EfficientNet como backbone:

```python
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights

def get_model_efficientnet_fasterrcnn(num_classes):
    backbone = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)
    # Adaptar para Faster R-CNN...
```

#### Otros backbones clÃ¡sicos a probar:
- ResNet-50 (mÃ¡s profundo)
- MobileNetV3 (mÃ¡s ligero)
- VGG-16 (arquitectura clÃ¡sica)

### 2. ComparaciÃ³n con Vision Transformers

Para tu lÃ­nea de investigaciÃ³n principal, el siguiente paso serÃ­a:

#### DINOv2 + Detection Head

```python
# Ejemplo conceptual
from transformers import AutoModel

backbone = AutoModel.from_pretrained("facebook/dinov2-base")
# Adaptar para detecciÃ³n...
```

**Ventajas de ViT vs CNN:**
- Mejor capacidad de atenciÃ³n global
- Mejores features para defectos pequeÃ±os
- Transfer learning mÃ¡s efectivo

### 3. AnÃ¡lisis Comparativo

Crear una tabla comparativa con:

| Modelo | Backbone | mAP | Params | Inference Time | GPU Memory |
|--------|----------|-----|--------|----------------|------------|
| ResNet-18 + Faster R-CNN | ResNet-18 | ? | 11M | ? | ? |
| ResNet-50 + Faster R-CNN | ResNet-50 | ? | 25M | ? | ? |
| EfficientNet + Faster R-CNN | EfficientNet-B0 | ? | 5M | ? | ? |
| DINOv2 + Detection Head | ViT-B | ? | 86M | ? | ? |

### 4. Mejoras del Dataset

- **Augmentation adicional**: rotaciones, flips, cambios de brillo
- **Balanceo de clases**: tÃ©cnicas de re-sampling o loss weighting
- **DetecciÃ³n de falsos positivos**: anÃ¡lisis de errores comunes

### 5. AnÃ¡lisis de Errores

Crear un notebook para:
- Visualizar casos donde el modelo falla
- Analizar confusiones entre categorÃ­as
- Identificar patrones en errores (tamaÃ±o, ubicaciÃ³n, etc.)

## ðŸ“ Notas Importantes

### Sobre ResNet-18 vs Hugging Face

El cÃ³digo inicial que mencionaste usa `AutoModelForImageClassification`, que es para **clasificaciÃ³n de imÃ¡genes**, no detecciÃ³n de objetos. La diferencia es:

- **ClasificaciÃ³n**: Una etiqueta por imagen (ej: "esta imagen contiene un perro")
- **DetecciÃ³n**: MÃºltiples objetos con ubicaciÃ³n (ej: "hay un perro en [x,y,w,h] y un gato en [x2,y2,w2,h2]")

Para detecciÃ³n, usamos:
1. **Backbone** (ResNet-18): Extrae features de la imagen
2. **RPN** (Region Proposal Network): Propone regiones candidatas
3. **ROI Head**: Clasifica y refina las regiones

### NormalizaciÃ³n de ImÃ¡genes

Usamos la normalizaciÃ³n estÃ¡ndar de ImageNet:
```python
mean=[0.485, 0.456, 0.406]
std=[0.229, 0.224, 0.225]
```

Esto es importante porque ResNet-18 fue preentrenado con estas estadÃ­sticas.

### Formato de Anotaciones

El dataset usa formato COCO con bounding boxes en formato `[x, y, width, height]`, que se convierten a `[x_min, y_min, x_max, y_max]` para PyTorch.

## ðŸ› Troubleshooting

### Error: CUDA out of memory
```bash
# Reducir batch size
--batch-size 2

# O usar CPU
CUDA_VISIBLE_DEVICES="" python train_resnet18_fasterrcnn.py ...
```

### Error: Invalid bbox (width or height <= 0)
El dataset loader filtra automÃ¡ticamente bboxes invÃ¡lidos. Verifica que tus anotaciones sean correctas.

### PÃ©rdida no converge
- Verificar learning rate (probar 0.001 o 0.01)
- Verificar que el dataset estÃ© correctamente cargado
- Aumentar nÃºmero de Ã©pocas
- Verificar que el backbone estÃ© preentrenado

### mAP muy bajo (<0.2)
- Aumentar Ã©pocas de entrenamiento
- Verificar score_threshold (probar 0.3)
- Revisar quality del dataset (anotaciones correctas)
- Usar backbone preentrenado

## ðŸ“š Referencias

- **Faster R-CNN**: Ren et al., "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks" (2015)
- **ResNet**: He et al., "Deep Residual Learning for Image Recognition" (2016)
- **TorchVision Detection**: https://pytorch.org/vision/stable/models.html#object-detection
- **COCO Format**: https://cocodataset.org/#format-data

## ðŸ“§ Contacto

Para dudas sobre el cÃ³digo o sugerencias de mejora, no dudes en contactar.

---

**Ã‰xito con tu TFG! ðŸŽ“ðŸš€**