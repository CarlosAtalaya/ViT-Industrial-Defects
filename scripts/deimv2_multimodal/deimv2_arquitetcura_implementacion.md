# DEIMv2 + Multimodal: Arquitectura de Implementaci√≥n

## üéØ Objetivo
Adaptar DEIMv2 (DINOv3 + detecci√≥n) para tu dataset industrial (6 clases de defectos) con extensi√≥n multimodal visi√≥n-texto.

---

## üìÅ Estructura de Directorios Propuesta

```
scripts/
‚îú‚îÄ‚îÄ resnet18/              # ‚úÖ Existente - baseline
‚îú‚îÄ‚îÄ efficientnet/          # ‚úÖ Existente - baseline
‚îî‚îÄ‚îÄ deimv2_industrial/     # üÜï NUEVO - Tu implementaci√≥n
    ‚îú‚îÄ‚îÄ configs/
    ‚îÇ   ‚îî‚îÄ‚îÄ deimv2_industrial_defects.yml    # Config adaptado
    ‚îú‚îÄ‚îÄ data/
    ‚îÇ   ‚îú‚îÄ‚îÄ industrial_dataset.py            # Wrapper CocoDetection
    ‚îÇ   ‚îî‚îÄ‚îÄ class_descriptions.py            # Textos por clase
    ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îî‚îÄ‚îÄ text_fusion.py                   # üÜï M√≥dulo multimodal (OPCIONAL fase 2)
    ‚îú‚îÄ‚îÄ train_deimv2.py                      # Script entrenamiento
    ‚îú‚îÄ‚îÄ evaluate_deimv2.py                   # Script evaluaci√≥n
    ‚îú‚îÄ‚îÄ visualize_attention.py               # Attention maps
    ‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Plan de Implementaci√≥n (2 Fases)

### **FASE 1: DEIMv2 Vanilla (PRIORIDAD)**
**Objetivo**: Validar que DEIMv2 funciona con tu dataset antes de multimodal.

#### 1.1 Archivo Config (`deimv2_industrial_defects.yml`)
```yaml
# Heredar de config base de DEIMv2-S
__include__: [
  '../../../configs/dataset/custom_detection.yml',
  '../../../configs/deimv2/deimv2_dinov3_s_coco.yml',
]

# Adaptaciones
num_classes: 6  # PERFORACIONES, RAYONES, ROTURA, DEFORMACIONES, CONTAMINACION, NORMAL
remap_mscoco_category: False

train_dataloader:
  total_batch_size: 4  # RTX 4070 -> batch 2 x 2 GPUs simuladas
  dataset:
    img_folder: /ruta/a/tu/dataset/train
    ann_file: /ruta/a/tu/dataset/annotations/instances_train.json

val_dataloader:
  dataset:
    img_folder: /ruta/a/tu/dataset/val
    ann_file: /ruta/a/tu/dataset/annotations/instances_val.json

# Backbone DINOv3
DINOv3STAs:
  weights_path: ./ckpts/vitt_distill.pt  # Descargar ViT-Tiny distilled

# Epochs reducidos para tu dataset peque√±o
epoches: 50
flat_epoch: 25
no_aug_epoch: 6
```

#### 1.2 Dataset Wrapper (`data/industrial_dataset.py`)
```python
# Reutilizar CocoDetection de DEIMv2
from engine.data.coco import CocoDetection

# Tu dataset ya est√° en formato COCO ‚Üí usar directamente
# Solo necesitas verificar compatibilidad de IDs de categor√≠as
```

#### 1.3 Script Entrenamiento (`train_deimv2.py`)
```python
# Copiar estructura de train.py del repo DEIMv2
# Cambiar: cargar tu config custom en lugar de COCO
# Comando:
# CUDA_VISIBLE_DEVICES=0 python train_deimv2.py \
#   -c configs/deimv2_industrial_defects.yml \
#   --use-amp --seed=0
```

**Resultado Esperado FASE 1**: 
- mAP > 40 en tu dataset (comparable a ResNet/EfficientNet)
- Validar que DINOv3 funciona mejor en defectos peque√±os

---

### **FASE 2: Extensi√≥n Multimodal (SOLO SI FASE 1 FUNCIONA)**

#### 2.1 Descripciones Textuales (`data/class_descriptions.py`)
```python
CLASS_DESCRIPTIONS = {
    "PERFORACIONES": "Agujero circular u orificio visible en la superficie del material",
    "RAYONES_ARANAZOS": "L√≠nea fina y alargada de da√±o superficial en el recubrimiento",
    "ROTURA_FRACTURA": "Grieta profunda o ruptura completa del material estructural",
    "DEFORMACIONES": "Alteraci√≥n de la forma original con abombamiento o hundimiento",
    "CONTAMINACION": "Presencia de part√≠culas extra√±as o manchas en la superficie",
    "NORMAL": "Superficie sin defectos visibles ni anomal√≠as"
}
```

#### 2.2 M√≥dulo Fusi√≥n Visi√≥n-Texto (`models/text_fusion.py`)
```python
# Encoder texto: CLIP o SigLIP
from transformers import CLIPTextModel, CLIPTokenizer

class MultimodalFusion(nn.Module):
    def __init__(self, visual_dim=192, text_dim=512, num_classes=6):
        # Proyectar embeddings visuales y textuales a espacio com√∫n
        self.visual_proj = nn.Linear(visual_dim, 256)
        self.text_proj = nn.Linear(text_dim, 256)
        self.fusion = nn.Linear(512, num_classes)
    
    def forward(self, visual_feats, text_embeds):
        # Similitud coseno + clasificaci√≥n
        v = F.normalize(self.visual_proj(visual_feats))
        t = F.normalize(self.text_proj(text_embeds))
        fused = torch.cat([v, t], dim=-1)
        return self.fusion(fused)
```

#### 2.3 Entrenamiento Incremental
```bash
# 1. Entrenar DEIMv2 base (FASE 1)
python train_deimv2.py -c configs/base.yml

# 2. Fine-tune con fusi√≥n multimodal
python train_deimv2_multimodal.py \
  -c configs/multimodal.yml \
  -r outputs/deimv2_base/best.pth  # Cargar pesos fase 1
```

---

## ‚öôÔ∏è Configuraci√≥n Hardware (RTX 4070)

```yaml
# Par√°metros ajustados para tu GPU
train_dataloader:
  total_batch_size: 4      # 2 im√°genes reales (simular 2 GPUs)
  num_workers: 4

# Modelo
DINOv3STAs:
  name: vit_tiny            # 192 dim - 9.7M params ‚Üí cabe en 12GB
  
# Entrenamiento
use_amp: True              # Mixed precision ‚Üí ahorra VRAM
gradient_checkpointing: True  # Si necesitas m√°s memoria
```

---

## üìä Comparaci√≥n Esperada

| Modelo | mAP | Params | VRAM | Notas |
|--------|-----|--------|------|-------|
| ResNet-18 (baseline) | ~42 | 11M | 6GB | Tu resultado actual |
| EfficientNet (baseline) | ~45 | 5M | 5GB | Tu resultado actual |
| **DEIMv2-S (FASE 1)** | **~50** | **9.7M** | **10GB** | DINOv3 + STA + Dense O2O |
| **DEIMv2-S + Multimodal (FASE 2)** | **~53** | **10.5M** | **11GB** | + Fusi√≥n texto |

---

## ‚úÖ Checklist Implementaci√≥n

### FASE 1 (Semana 1-2):
- [ ] Clonar repo DEIMv2: `git clone https://github.com/Intellindust-AI-Lab/DEIMv2`
- [ ] Descargar ViT-Tiny distilled: `vitt_distill.pt` ‚Üí `./ckpts/`
- [ ] Crear `configs/deimv2_industrial_defects.yml`
- [ ] Verificar formato COCO de tu dataset
- [ ] Entrenar 10 epochs de prueba ‚Üí verificar convergencia
- [ ] Entrenar 50 epochs completo
- [ ] Comparar mAP con ResNet/EfficientNet

### FASE 2 (Semana 3-4) - SOLO SI FASE 1 OK:
- [ ] Implementar `class_descriptions.py`
- [ ] Implementar `MultimodalFusion` module
- [ ] Fine-tune con fusi√≥n visi√≥n-texto
- [ ] Comparar mAP multimodal vs vanilla

---

## üéì Para el TFG

**Contribuci√≥n t√©cnica clara**:
1. **Adaptaci√≥n de DEIMv2 a dominio industrial** (no est√° en paper original)
2. **Extensi√≥n multimodal custom** (tu aportaci√≥n principal)
3. **Benchmarking exhaustivo** (CNN vs ViT vs Multimodal)

**Estructura memoria**:
- Cap 4: Implementaci√≥n DEIMv2 vanilla en defectos industriales
- Cap 5: Propuesta extensi√≥n multimodal con embeddings texto
- Cap 6: Resultados comparativos (tablas mAP, gr√°ficas atenci√≥n)

---

## üö® Decisi√≥n Cr√≠tica AHORA

**¬øEmpezamos con FASE 1 (DEIMv2 vanilla) o quieres ir directo a multimodal?**

**Recomendaci√≥n**: FASE 1 primero. Razones:
1. Validar que DEIMv2 funciona con tu dataset
2. Baseline s√≥lido para comparar multimodal
3. Menos riesgo de bugs complejos
4. Si FASE 2 falla, FASE 1 ya es contribuci√≥n v√°lida

**Siguiente paso**: ¬øCreo el archivo `deimv2_industrial_defects.yml` completo?