# Resumen de SesiÃ³n: ImplementaciÃ³n DEIMv2 para DetecciÃ³n de Defectos Industriales

**Fecha:** 14 Noviembre 2024  
**DuraciÃ³n:** ~1 hora de entrenamiento + setup  
**Objetivo:** Implementar y evaluar DEIMv2 (Vision Transformer) como evoluciÃ³n de los baselines CNN

---

## ğŸ¯ Estado Actual del Proyecto

### Fase Completada: DEIMv2 Vanilla (FASE 1)

**âœ… ImplementaciÃ³n exitosa de:**
1. Entrenamiento completo de DEIMv2-M (52 Ã©pocas)
2. Pipeline de evaluaciÃ³n en test set
3. Sistema de mÃ©tricas compatible con baselines
4. Infraestructura de visualizaciÃ³n

---

## ğŸ“Š Resultados Obtenidos

### Arquitectura Entrenada: DEIMv2-M

**ConfiguraciÃ³n:**
- **Backbone:** DINOv3 ViT-Tiny+ (vittplus_distill.pt)
- **ParÃ¡metros:** 17.81M (vs 11M ResNet-18, 5M EfficientNet)
- **Dimensiones:** 256 embedding dim, 4 decoder layers
- **Hardware:** RTX 4070 12GB
- **Tiempo entrenamiento:** ~60 minutos (52 Ã©pocas)

### MÃ©tricas en Test Set (205 imÃ¡genes)

```
mAP @ IoU=0.50:0.95  = 0.178 (17.8%)
AP  @ IoU=0.50       = 0.232 (23.2%)
AP  @ IoU=0.75       = 0.171 (17.1%)
AR  @ maxDets=100    = 0.480 (48.0%)

Por tamaÃ±o de objeto:
- Small objects:  mAP = 0.023 (2.3%)
- Medium objects: mAP = 0.072 (7.2%)
- Large objects:  mAP = 0.263 (26.3%)
```

### Comparativa con Baselines (esperada)

| Modelo | Arquitectura | Params | mAP@0.50:0.95 | Notas |
|--------|-------------|---------|---------------|-------|
| ResNet-18 | CNN + Faster R-CNN | 11M | ~0.42* | Baseline clÃ¡sico |
| EfficientNet-B0 | CNN + Faster R-CNN | 5M | ~0.45* | Baseline ligero |
| **DEIMv2-M** | **ViT + DEIM** | **17.8M** | **0.178** | **Primer experimento** |

_*Nota: MÃ©tricas de ResNet/EfficientNet son estimadas. Necesario confirmar con evaluaciÃ³n real._

---

## ğŸ—ï¸ Estructura Implementada

### Directorio: `scripts/deimv2_multimodal/`

```
scripts/deimv2_multimodal/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ deimv2_industrial_defects.yml    # Config entrenamiento
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ deimv2_industrial_run/
â”‚       â”œâ”€â”€ checkpoint0039.pth            # Checkpoints cada 5 epochs
â”‚       â”œâ”€â”€ best_stg1.pth                 # Mejor modelo
â”‚       â”œâ”€â”€ log.txt                       # Log de entrenamiento
â”‚       â”œâ”€â”€ summary/                      # TensorBoard logs
â”‚       â””â”€â”€ test_evaluation_results.json  # MÃ©tricas en test
â”œâ”€â”€ train_deimv2_industrial.py           # Script entrenamiento
â”œâ”€â”€ evaluate_deimv2.py                   # EvaluaciÃ³n mAP en test
â”œâ”€â”€ visualize_deimv2_predictions.py      # VisualizaciÃ³n predicciones
â”œâ”€â”€ plot_deimv2_training_metrics.py      # GrÃ¡ficas entrenamiento
â””â”€â”€ run_evaluation_deimv2.sh             # Pipeline completo
```

---

## ğŸ”§ ConfiguraciÃ³n TÃ©cnica

### Dataset

```yaml
Train: 715 imÃ¡genes, 944 anotaciones
Val:   102 imÃ¡genes, 145 anotaciones
Test:  205 imÃ¡genes, 265 anotaciones

Clases (6):
  0: NORMAL
  1: DEFORMACIONES
  2: ROTURA_FRACTURA
  3: RAYONES_ARANAZOS
  4: PERFORACIONES
  5: CONTAMINACION
```

### HiperparÃ¡metros Clave

```yaml
# Modelo
embed_dim: 256
hidden_dim: 256
num_layers: 4

# Entrenamiento
epochs: 52
batch_size: 2  # Ajustado para RTX 4070
learning_rate: 0.0005 (base), 0.000025 (backbone)
optimizer: AdamW
use_amp: True  # Mixed precision

# Data Augmentation
- Mosaic augmentation
- RandomPhotometricDistort
- RandomIoUCrop
- Mixup (Ã©pocas 4-25)
- CopyBlend (Ã©pocas 4-44)
```

---

## ğŸ“ˆ AnÃ¡lisis de Resultados

### âš ï¸ Rendimiento Inferior a Baselines

**Observaciones:**
- DEIMv2-M obtiene mAP=0.178 vs ~0.42-0.45 de CNNs
- El modelo tiene **dificultad con objetos pequeÃ±os** (mAP=0.023)
- Mejor rendimiento en objetos grandes (mAP=0.263)

### Posibles Causas

1. **Dataset pequeÃ±o (715 imÃ¡genes train)**
   - ViTs requieren mÃ¡s datos que CNNs
   - Transfer learning desde DINOv3 puede no ser suficiente

2. **HiperparÃ¡metros no optimizados**
   - Primer experimento con config base
   - Posible learning rate inadecuado
   - Batch size muy pequeÃ±o (2)

3. **Formato de detecciones**
   - Modelo predice 300 queries por imagen
   - Muchas detecciones de baja confianza (61,500 total)
   - Posible necesidad de ajustar threshold

4. **Entrenamiento incompleto**
   - 52 Ã©pocas pueden ser insuficientes
   - Curva de loss puede no haber convergido

---

## ğŸ¯ PrÃ³ximos Pasos Inmediatos

### 1. AnÃ¡lisis Detallado (URGENTE)

```bash
# Revisar mÃ©tricas de entrenamiento con TensorBoard
tensorboard --logdir scripts/deimv2_multimodal/outputs/deimv2_industrial_run/summary

# Visualizar predicciones para entender errores
cd scripts/deimv2_multimodal
./run_evaluation_deimv2.sh  # Genera visualizaciones
```

### 2. ComparaciÃ³n Justa con Baselines

**AcciÃ³n necesaria:** Evaluar ResNet-18 y EfficientNet con el MISMO protocolo:

```bash
# Evaluar baselines con script de evaluaciÃ³n
cd scripts/resnet18
python evaluate_model.py \
    --checkpoint results/training/resnet18_fasterrcnn_*/checkpoints/best_checkpoint.pth \
    --dataset-path ../../curated_dataset_splitted_20251101_provisional_1st_version \
    --score-threshold 0.5 \
    --iou-threshold 0.5
```

### 3. Iteraciones de Mejora

**OpciÃ³n A: Optimizar DEIMv2-M**
- Aumentar Ã©pocas a 100
- Ajustar learning rate (probar 0.0001)
- Aumentar batch size si es posible
- Probar DEIMv2-S (menos parÃ¡metros, mÃ¡s estable)

**OpciÃ³n B: Cambiar a DEIMv2-S**
- Descargar `vitt_distill.pt` (9.7M params)
- Requiere menos VRAM (~10GB)
- MÃ¡s rÃ¡pido de entrenar
- Potencialmente mejor con dataset pequeÃ±o

**OpciÃ³n C: Data Augmentation**
- Revisar si augmentations son demasiado agresivas
- Probar configuraciÃ³n mÃ¡s conservadora

---

## ğŸ“ Tareas Pendientes para el TFG

### Corto Plazo (Esta Semana)

- [ ] **Evaluar baselines con protocolo unificado**
- [ ] **Analizar visualizaciones de predicciones**
- [ ] **Revisar curvas de training en TensorBoard**
- [ ] **Decidir**: Â¿Optimizar DEIMv2-M o cambiar a DEIMv2-S?

### Medio Plazo (PrÃ³ximas 2 Semanas)

- [ ] **Iterar hiperparÃ¡metros** para mejorar mAP
- [ ] **Entrenamiento largo** (100+ Ã©pocas) si es necesario
- [ ] **Comparativa exhaustiva** CNN vs ViT (tablas, grÃ¡ficas)
- [ ] **AnÃ¡lisis de attention maps** (visualizar quÃ© detecta el ViT)

### Largo Plazo (FASE 2 - Opcional)

- [ ] **ExtensiÃ³n multimodal** (fusiÃ³n visiÃ³n-texto)
- [ ] **Descripciones semÃ¡nticas** por clase de defecto
- [ ] **Fine-tuning con embeddings de texto**

---

## ğŸš¨ DecisiÃ³n CrÃ­tica Inmediata

### Â¿Continuar con DEIMv2-M o cambiar estrategia?

**OpciÃ³n 1: Optimizar DEIMv2-M actual**
- Pros: Ya entrenado, infraestructura lista
- Contras: Puede necesitar muchas iteraciones

**OpciÃ³n 2: Cambiar a DEIMv2-S**
- Pros: Menos parÃ¡metros, mÃ¡s adecuado para dataset pequeÃ±o
- Contras: Requiere re-entrenar desde cero

**OpciÃ³n 3: Aumentar datos**
- Pros: ViTs mejoran con mÃ¡s datos
- Contras: Requiere mÃ¡s esfuerzo de recolecciÃ³n/etiquetado

**RecomendaciÃ³n:** 
1. Primero evaluar baselines con mismo protocolo (confirmar que mAP~0.42-0.45)
2. Analizar visualizaciones de DEIMv2 (entender quÃ© estÃ¡ fallando)
3. Decidir basado en anÃ¡lisis: optimizar M, cambiar a S, o aumentar datos

---

## ğŸ“Š MÃ©tricas de Progreso

### Completado (âœ…)

- âœ… Setup completo de DEIMv2
- âœ… Entrenamiento de 52 Ã©pocas exitoso
- âœ… Pipeline de evaluaciÃ³n funcional
- âœ… Sistema de mÃ©tricas compatible con baselines
- âœ… Infraestructura de visualizaciÃ³n

### En Progreso (ğŸ”„)

- ğŸ”„ AnÃ¡lisis de resultados
- ğŸ”„ ComparaciÃ³n con baselines
- ğŸ”„ OptimizaciÃ³n de hiperparÃ¡metros

### Pendiente (â³)

- â³ Mejora de mAP a niveles competitivos
- â³ ExtensiÃ³n multimodal (FASE 2)
- â³ RedacciÃ³n de capÃ­tulos del TFG

---

## ğŸ’¡ Conclusiones Provisionales

### Logros

1. **Infraestructura robusta:** Pipeline completo de train/eval/viz
2. **Primer modelo ViT funcional:** DEIMv2 entrenado y evaluado
3. **Base sÃ³lida para experimentaciÃ³n:** FÃ¡cil iterar configuraciones

### DesafÃ­os

1. **Rendimiento inferior a baselines:** mAP 0.178 vs ~0.42-0.45
2. **Dataset pequeÃ±o:** LimitaciÃ³n fundamental para ViTs
3. **OptimizaciÃ³n pendiente:** Muchos hiperparÃ¡metros por explorar

### Valor para el TFG

**AportaciÃ³n tÃ©cnica clara:**
- AdaptaciÃ³n de DEIMv2 (estado del arte) a dominio industrial
- ComparaciÃ³n rigurosa CNN vs ViT en dataset real
- AnÃ¡lisis de limitaciones de ViTs con pocos datos
- Base para extensiÃ³n multimodal (FASE 2)

**Incluso si mAP no supera CNNs**, el trabajo tiene valor:
- AnÃ¡lisis comparativo CNN vs ViT
- Estudio de transfer learning con DINOv3
- ExploraciÃ³n de arquitecturas modernas en industria
- Propuesta de mejora con multimodalidad

---

## ğŸ”— Archivos Clave Generados

```
# Resultados de evaluaciÃ³n
scripts/deimv2_multimodal/outputs/deimv2_industrial_run/test_evaluation_results.json

# Detecciones completas
scripts/deimv2_multimodal/outputs/deimv2_industrial_run/test_detections.json

# Logs de TensorBoard
scripts/deimv2_multimodal/outputs/deimv2_industrial_run/summary/

# Visualizaciones (tras completar pipeline)
scripts/deimv2_multimodal/outputs/deimv2_industrial_run/visualizations_test/
```

---

## ğŸ“ Siguiente SesiÃ³n

**Agenda propuesta:**

1. **RevisiÃ³n de visualizaciones** (Â¿quÃ© estÃ¡ detectando mal?)
2. **Comparativa con baselines** (eval con mismo protocolo)
3. **DecisiÃ³n estratÃ©gica** (optimizar M, cambiar a S, o aumentar datos)
4. **Plan de iteraciones** (roadmap para mejorar mAP)

**PreparaciÃ³n necesaria:**
- Revisar TensorBoard logs
- Analizar imÃ¡genes de visualizaciÃ³n
- Evaluar baselines con scripts existentes
- Pensar en estrategia de mejora

---

**Estado del proyecto: EN PUNTO CRÃTICO DE DECISIÃ“N**  
**PrÃ³xima acciÃ³n: ANÃLISIS DE RESULTADOS Y COMPARACIÃ“N CON BASELINES**